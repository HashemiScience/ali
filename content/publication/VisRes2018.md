+++
title = "The role of horizontal facial structure on the N170 and N250"
date = 2018
draft = false

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["Ali Hashemi", "Matthew V Pachai", "Patrick J Bennett", "Allison B Sekuler"]

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference paper
# 2 = Journal article
# 3 = Manuscript
# 4 = Report
# 5 = Book
# 6 = Book section
publication_types = ["2"]

# Publication name and optional abbreviated version.
publication = "In *Vision Research*."
publication_short = "In *Vis Res*"

# Abstract and optional shortened version.
abstract = "Recent studies have shown that horizontal facial structure is important for face identification (Dakin and Watt, 2009; Goffaux and Dakin, 2010). Also, sensitivity to horizontal structure is associated with the size of the face inversion effect (Pachai et al., 2013). However, it is unclear how the N170 and N250, two components of visual event-related potentials ERPs that have been implicated in face perception, are modulated by oriented facial structure in an upright face identification task. Here, we recorded ERPs and behavioural accuracy from adult observers performing a 1-of-6 face identification task in conditions that parametrically manipulated the orientation structure of upright faces. Faces were filtered with ideal orientation filters centred on either 0 (horizontal) or 90 deg (vertical). Filter bandwidth was varied across conditions from +/- 45 to +/- 90 deg in steps of +/- 9 deg. As has been reported previously, response accuracy was significantly higher for faces that contained horizontal structure than vertical structure, and the horizontal-vertical difference was correlated with accuracy for unfiltered faces. In addition, the N170 and N250 were affected by the manipulation of horizontal facial structure. Furthermore, for the N250, but not the N170, the relative sensitivity to horizontal compared to vertical facial structure was significantly correlated with identification accuracy for unfiltered faces. We suggest that in a face identification task, the N250 but not the N170 is modulated by the amount of diagnostic information conveyed by horizontal structure."

# Featured image thumbnail (optional)
image_preview = ""

# Is this a selected publication? (true/false)
selected = false

# Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's filename without extension.
#   E.g. `projects = ["deep-learning"]` references `content/project/deep-learning.md`.
#   Otherwise, set `projects = []`.
# projects = ["example-external-project"]
projects = ["face-perception"]

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = []

# Links (optional).
url_pdf = "https://doi.org/10.1016/j.visres.2018.02.006"
url_preprint = "#"
url_code = "#"
url_dataset = "#"
url_project = "#"
url_slides = "#"
url_video = "#"
url_poster = "#"
url_source = "#"

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
# url_custom = [{name = "Custom Link", url = "http://example.org"}]

# Does this page contain LaTeX math? (true/false)
math = true

# Does this page require source code highlighting? (true/false)
highlight = true

# Featured image
# Place your image in the `static/img/` folder and reference its filename below, e.g. `image = "example.jpg"`.
#[header]
#image = "headers/fig1a_allStimuli.png"
#caption = "Figure 1 from paper"

+++

#More detail can easily be written here using *Markdown* and $\rm \LaTeX$ math code.
